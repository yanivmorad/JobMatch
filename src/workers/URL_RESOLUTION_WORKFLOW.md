# URL Resolution Workflow - Updated

## Problem Solved

**Previous Issue**: The worker was resolving HireMeTech URLs twice:
1. First resolution in the worker to check for duplicates
2. Second resolution inside `scraper.scrape()` during actual scraping
3. This wasted time and resources

**New Solution**: Two-pass approach
1. **First pass**: Resolve URL, update database, continue to next job
2. **Second pass**: Worker picks up the updated URL and scrapes it (no resolution needed)

## New Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ITERATION 1: URL Resolution & Database Update              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job URL: https://hiremetech.com/job/123
Status: WAITING_FOR_SCRAPE
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Detect: Is this HireMeTech?            â”‚
â”‚ â†’ YES                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resolve URL                            â”‚
â”‚ Result: https://greenhouse.io/job/456  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check: Does greenhouse URL exist?      â”‚
â”‚ â†’ NO (new job)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UPDATE DATABASE:                       â”‚
â”‚ - url = https://greenhouse.io/job/456  â”‚
â”‚ - status = WAITING_FOR_SCRAPE          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    CONTINUE to next job
    (Don't scrape yet!)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ITERATION 2: Actual Scraping (Next Worker Cycle)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job URL: https://greenhouse.io/job/456  â† Updated!
Status: WAITING_FOR_SCRAPE
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Detect: Is this HireMeTech?            â”‚
â”‚ â†’ NO (already resolved!)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCRAPE THE URL                         â”‚
â”‚ - Jina AI (primary)                    â”‚
â”‚ - Playwright (fallback)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SAVE TO DATABASE:                      â”‚
â”‚ - full_description                     â”‚
â”‚ - company                              â”‚
â”‚ - job_title                            â”‚
â”‚ - status = WAITING_FOR_AI              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    âœ… DONE!
```

## Code Changes

### 1. `db/jobs_repository.py`
Added new function:
```python
async def update_job_url(job_id: int, new_url: str):
    """
    Update the URL for a job (e.g., when HireMeTech URL resolves to company URL).
    Also resets status to WAITING_FOR_SCRAPE so the worker picks it up again.
    """
    pool = await get_pool()
    await pool.execute(
        """
        UPDATE jobs 
        SET url = $1, status = 'WAITING_FOR_SCRAPE'
        WHERE id = $2
        """,
        new_url,
        job_id,
    )
```

### 2. `workers/worker_manager.py`
Updated logic:

**When HireMeTech URL is detected:**
1. Resolve to company URL
2. Check if company URL exists in DB
3. If duplicate â†’ delete and skip
4. If new â†’ **UPDATE URL in DB and continue** (don't scrape yet!)

**When normal URL is detected:**
1. Scrape directly (no resolution needed)

## Benefits

âœ… **No Double Resolution**: URL is resolved only once  
âœ… **Clean Separation**: Resolution and scraping are separate steps  
âœ… **Database Always Accurate**: URL is updated before scraping  
âœ… **Better Logging**: Clear visibility into what's happening  
âœ… **Easier Debugging**: Each step is isolated  

## Example Logs

### Iteration 1: Resolution
```
ğŸ•·ï¸ Processing: https://hiremetech.com/job/123
ğŸ” Detected HireMeTech URL, resolving...
âœ… Resolved: https://hiremetech.com/job/123 â†’ https://greenhouse.io/job/456
ğŸ“ Updating job URL in database: https://hiremetech.com/job/123 â†’ https://greenhouse.io/job/456
âœ“ URL updated. Continuing to next job - worker will pick this up again with new URL.
```

### Iteration 2: Scraping
```
ğŸ•·ï¸ Processing: https://greenhouse.io/job/456
ğŸ•·ï¸ Scraping: https://greenhouse.io/job/456
ğŸ“¡ Scraping via Jina: https://greenhouse.io/job/456
âœ… Scrape complete for: https://greenhouse.io/job/456
```

## Duplicate Detection

If the resolved URL already exists:
```
ğŸ•·ï¸ Processing: https://hiremetech.com/job/123
ğŸ” Detected HireMeTech URL, resolving...
âœ… Resolved: https://hiremetech.com/job/123 â†’ https://greenhouse.io/job/456
â­ï¸ DUPLICATE DETECTED: Resolved URL 'https://greenhouse.io/job/456' 
   already exists in DB (Job ID: 42). Deleting duplicate job ID 89.
```

## Why This Approach?

1. **Separation of Concerns**: Resolution is a separate step from scraping
2. **Database Integrity**: URL is always correct before scraping
3. **Idempotent**: If worker crashes, it can resume cleanly
4. **Efficient**: No wasted resolution cycles
5. **Extensible**: Easy to add more resolution logic for other sites
