import os
import re
import time
from typing import Optional

import requests
from dotenv import load_dotenv

try:
    from markdownify import markdownify as md
    from playwright.sync_api import sync_playwright

    HAS_PLAYWRIGHT = True
except ImportError:
    HAS_PLAYWRIGHT = False

load_dotenv()


class Scraper:
    def __init__(self):
        self.session = requests.Session()
        self.api_key = os.getenv("JINA_API_KEY")
        self.hireme_token = os.getenv("HIRE_ME_TECH_TOKEN")

        if not self.api_key:
            raise ValueError("âŒ JINA_API_KEY missing!")

        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "X-Timeout": "40",
            "X-With-Iframe": "true",
            "X-With-Shadow-Dom": "true",
        }

    # --- ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ× ×™×§×•×™ ×•×ª×§×™× ×•×ª ---
    def is_content_valid(self, text: str) -> bool:
        if not text or len(text) < 250:
            return False
        invalid_markers = ["access denied", "robot check", "captcha", "404 not found"]
        return not any(marker in text.lower() for marker in invalid_markers)

    def clean_text(self, text: str) -> str:
        if not text:
            return ""
        text = re.sub(r"^>?\s*https?://[^\n]+\n?", "", text, flags=re.MULTILINE)
        text = re.sub(r"!\[.*?\]\(.*?\)", "", text)
        text = re.sub(r"\n{3,}", "\n\n", text)
        return text.strip()

    # --- ×˜×™×¤×•×œ ××™×•×—×“ ×‘××ª×¨×™× ×¡×¤×¦×™×¤×™×™× (The Resolvers) ---

    def _resolve_hiremetech(self, url: str) -> str:
        """××–×¨×™×§ ×˜×•×§×Ÿ, ×œ×•×—×¥ ×¢×œ ×›×¤×ª×•×¨ ×•××—×–×™×¨ ××ª ×”-URL ×”×¡×•×¤×™ ×©×œ ×”×—×‘×¨×”"""
        if not HAS_PLAYWRIGHT or not self.hireme_token:
            print("âš ï¸ Playwright missing or Token not set in .env")
            return url

        print(f"ğŸ”‘ ××‘×¦×¢ VIP Access ×¢×‘×•×¨ HireMeTech: {url}")
        try:
            with sync_playwright() as p:
                # ×‘×©×¨×ª × ×¨×™×¥ headless=True, ×‘×‘×“×™×§×•×ª ××§×•××™×•×ª ××¤×©×¨ False ×›×“×™ ×œ×¨××•×ª ××ª ×”×§×¡×
                browser = p.chromium.launch(headless=True)
                context = browser.new_context(viewport={"width": 1280, "height": 800})
                page = context.new_page()

                # 1. ×”×–×¨×§×ª ×”×˜×•×§×Ÿ - ×©×™× ×œ×‘ ×œ×ª×™×§×•×Ÿ ×œ-auth_token
                page.goto("https://hiremetech.com")
                page.evaluate(
                    f"localStorage.setItem('auth_token', '{self.hireme_token}')"
                )

                # 2. × ×™×•×•×˜ ×œ××©×¨×” ×•×”××ª× ×” ×œ×›×¤×ª×•×¨
                page.goto(url, wait_until="networkidle")
                apply_button = 'button:has-text("×”×’×© ××•×¢××“×•×ª")'

                # ××—×›×” ×©×”×›×¤×ª×•×¨ ×™×•×¤×™×¢ (×œ×¤×¢××™× ×œ×•×§×— ×¨×’×¢ ×œ-JS ×œ×”×ª×¨× ×“×¨)
                page.wait_for_selector(apply_button, timeout=10000)

                # 3. ×œ×—×™×¦×” ×—×›××”
                # ×”××ª×¨ ×‘×“×¨×š ×›×œ×œ ×¤×•×ª×— ×˜××‘ ×—×“×©. × ×ª×¤×•×¡ ××ª ×”-Event ×”×–×”.
                with context.expect_page() as new_page_info:
                    page.click(apply_button)

                new_page = new_page_info.value
                new_page.wait_for_load_state("networkidle")

                final_url = new_page.url
                print(f"ğŸš€ ×”×¦×œ×—× ×•! ×”×œ×™× ×§ ×”×××™×ª×™ ×”×•×: {final_url}")

                browser.close()
                return final_url
        except Exception as e:
            print(f"âŒ × ×›×©×œ ×‘×—×™×œ×•×¥ ×œ×™× ×§ (HireMeTech): {e}")
            return url

    # --- ×× ×’× ×•× ×™ ×”×¡×¨×™×§×” ×”××¨×›×–×™×™× ---

    def _scrape_with_playwright(self, url: str) -> Optional[str]:
        """×’×™×‘×•×™ ×œ××§×¨×” ×©-Jina ×œ× ××¦×œ×™×— ×œ×§×¨×•× ××ª ××ª×¨ ×”×™×¢×“"""
        if not HAS_PLAYWRIGHT:
            return None
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                page.goto(url, timeout=60000, wait_until="networkidle")
                content = md(page.content())
                browser.close()
                return content
        except:
            return None

    def scrape(self, url: str, retries: int = 2) -> Optional[dict]:
        """×”×¤×•× ×§×¦×™×” ×”××¨×›×–×™×ª ×©××ª×” ×§×•×¨× ×œ×”"""

        # --- ×©×œ×‘ 1: ×–×™×”×•×™ ×•×˜×™×¤×•×œ ×‘××ª×¨×™× ×¡×¤×¦×™×¤×™×™× ---
        target_url = url
        if "hiremetech.com" in url:
            resolved = self._resolve_hiremetech(url)
            # ×× ×”×œ×™× ×§ ×”×©×ª× ×”, × ××©×™×š ×œ×¡×¨×•×§ ××ª ×”×œ×™× ×§ ×”×—×“×©
            if resolved != url:
                target_url = resolved

        # --- ×©×œ×‘ 2: ×¡×¨×™×§×” ×‘×××¦×¢×•×ª Jina (×”××¡×œ×•×œ ×”××”×™×¨ ×•×”× ×§×™) ---
        jina_url = f"https://r.jina.ai/{target_url}"
        print(f"ğŸ“¡ ×¡×•×¨×§ ×‘×××¦×¢×•×ª Jina: {target_url}")

        for attempt in range(retries):
            try:
                headers = self.headers.copy()
                if attempt > 0:
                    headers["X-No-Cache"] = "true"

                res = self.session.get(jina_url, headers=headers, timeout=40)
                if res.status_code == 200 and self.is_content_valid(res.text):
                    return {
                        "source": "jina",
                        "url": target_url,
                        "full_description": self.clean_text(res.text),
                    }
            except Exception as e:
                print(f"âš ï¸ × ×™×¡×™×•×Ÿ Jina {attempt + 1} × ×›×©×œ: {e}")
            time.sleep(1)

        # --- ×©×œ×‘ 3: ×’×™×‘×•×™ Playwright (×”××¡×œ×•×œ ×”×›×‘×“) ---
        print("ğŸš¨ ×¢×•×‘×¨ ×œ×’×™×‘×•×™ Playwright ××œ×...")
        local_content = self._scrape_with_playwright(target_url)
        if local_content and self.is_content_valid(local_content):
            return {
                "source": "local_browser",
                "url": target_url,
                "full_description": self.clean_text(local_content),
            }

        return None


if __name__ == "__main__":
    scraper = Scraper()
    # ×‘×“×™×§×” ×¢×œ ×œ×™× ×§ ×©×œ HireMeTech
    test_url = "https://hiremetech.com/job/106273229"
    res = scraper.scrape(test_url)

    if res:
        print("\nâœ… ×¡×¨×™×§×” ×”×•×©×œ××”!")
        print(f"××§×•×¨: {res['source']}")
        print(f"×œ×™× ×§ ×™×¢×“: {res['url']}")
        print(f"×ª×•×›×Ÿ: {res['full_description'][:200]}...")
